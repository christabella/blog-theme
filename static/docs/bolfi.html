<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>Bayesian Optimization for Likelihood-Free Inference (BOLFI)</title>
<meta name="author" content="(Christabella Irwanto)"/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/reveal.js/3.0.0/css/reveal.css"/>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/reveal.js/3.0.0/css/theme/serif.css" id="theme"/>

<link rel="stylesheet" href="https://bella.cc/css/custom.css"/>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/reveal.js/3.0.0/lib/css/zenburn.css"/>
<!-- If the query includes 'print-pdf', include the PDF print sheet -->
<script>
    if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = 'https://cdn.jsdelivr.net/reveal.js/3.0.0/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    }
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<div class="reveal">
<div class="slides">
<section>
<section id="slide-sec-">
<h2 id="orgea98f90">BOLFI</h2>
<aside class="notes">
<p>
‚ÄúBayesian Optimization for Likelihood-Free Inference of Simulator-Based Statistical Models‚Äù (2016) by Michael U. Gutmann and Jukka Corander.
</p>

</aside>

<div class="figure">
<p><img src="/ox-hugo/screenshot_2019-11-05_21-41-08.png" alt="screenshot_2019-11-05_21-41-08.png" />
</p>
</div>
</section>
</section>
<section>
<section id="slide-sec-">
<h2 id="org7256792">Problem</h2>
<ul>
<li class="fragment appear"><b>Topic</b>: Statistical inference for models where:
<ul>
  <li class="fragment appear">The <span class="underline">likelihood \(p_{\mathbf{y}|\mathbf{\theta}}\) is intractable</span> üîÆ (e.g. analytical form is unknown/costly to compute).
    <ul>
      <li>\(\implies\) inference with likelihood \(\mathcal{L}(\mathbf{\theta}) = p_{\mathbf{y}|\mathbf{\theta}}(\mathbf{y}_o | \mathbf{\theta})\) is not possible.</li>

  </ul></li>
  <li class="fragment appear"><span class="underline">Simulating data</span> ü§ñ from the model is possible.
    <ul>
    <li>Using a simulator-based statistical model (implicit/generative model), i.e. a family of pdfs \(\left\{p_{\mathbf{y} \mid \mathbf{\theta}} \right\}_{\mathbf{\theta}}\) of unknown analytical form which allows for exact sampling of data \(\mathbf{y} \sim p(\mathbf{y}|\mathbf{\theta})\)</li>

</ul></li>

</ul></li>
<li class="fragment appear"><b>Inference principle</b>: Find parameter values \(\theta\) for which there is a small distance between 
  <ul>
    <li>the posterior of the simulated data \(\mathbf{y}\), and</li>
    <li>the observed data \(\mathbf{y}_o\).</li>

</ul></li>

</ul>
</section>
</section>
<section>
  <section id="slide-sec-">
    <h3 id="org46f871f">Other assumptions</h3>
    <ul>
      <li class="fragment appear">Only a small number of parameters are of interest (theta is low-dimensional)</li>
      <li class="fragment appear">Data generating process can be very complex</li>

    </ul>
  </section>
</section>
<section>
  <section id="slide-sec-">
    <h2 id="org8d1ca5d">Existing methods</h2>
    <p>
      For likelihood-free inference with simulator-based models, the basic idea is to identify model parameters by <span class="underline">finding values which yield simulated data that resemble the observed data</span>.
    </p>
    <ul>
      <li class="fragment appear">‚ÄúApproximate Bayesian computation‚Äù (ABC), originated in genetics üî¨</li>
      <li class="fragment appear">‚ÄúIndirect inference‚Äù, originated in economics üìà</li>
      <li class="fragment appear">‚ÄúSynthetic likelihood‚Äù, originated in ecology üå≤</li>

    </ul>
  </section>
</section>
<section>
  <section id="slide-sec-">
    <h3 id="org783be93">Conventional ABC</h3>
    <ul>
      <li class="fragment appear">‚ÄúBayesian forward modeling‚Äù, i.e. likelihood-free rejection sampling (LFRS)</li>
      <li class="fragment appear">Let \(\mathbf{y}_o\) be the observed data. For many iterations:
	<ol>
	  <li class="fragment appear">Sample \(\theta\) from proposal distribution \(q(\theta)\).</li>
	  <li class="fragment appear">Sample \(\mathbf{y}|\theta\) according to the data model.</li>
	  <li class="fragment appear">Compute distance \(d(\mathbf{y}, \mathbf{y}_o)\)</li>
	  <li class="fragment appear">Keep if  \(d(\mathbf{y}, \mathbf{y}_o) \leq \epsilon\); discard otherwise.</li>

      </ol></li>
      <li class="fragment appear">Different \(q(\theta)\) for different algorithms</li>
      <li class="fragment appear">If \(\epsilon\) is small enough, kept samples are samples from an approximate posterior</li>

    </ul>

  </section>
</section>
<section>
  <section id="slide-sec-">
    <h3 id="org61ce7ee">Implicit likelihood approximation</h3>
    <aside class="notes">
      <p>
	There is an implicit likelihood approximation going on here.
      </p>

    </aside>
    <ul>
      <li>Compute likelihood (probability of generating data like \(\mathbf{y}_o\) given hypothesis \(\theta\)) empirically
	<ul>
	  <li class="fragment appear">Proportion of kept (green) samples</li>
	  <li class="fragment appear">\(L(\theta) \approx \frac{1}{N} \sum_{i=1}^{N} \mathbb{1}\left(d\left(y_{o}^{(i)}, y^{\circ}\right) \leq \epsilon\right)\)</li>

      </ul></li>

    </ul>
    <p width="600">
      <img src="/ox-hugo/syw077f1_2019-11-05_09-45-05.png" alt="syw077f1_2019-11-05_09-45-05.png" width="600" />
      Image from <a class='org-ref-reference' href="#10.1093/sysbio/syw077">10.1093/sysbio/syw077</a>
    </p>
  </section>
</section>
<section>
  <section id="slide-sec-">
    <h3 id="orgcb6e07c">Downsides</h3>
    <p width="350">
      <img src="/ox-hugo/screenshot_2019-11-03_16-58-39.png" alt="screenshot_2019-11-03_16-58-39.png" width="350" />
      Image from <a class='org-ref-reference' href="#Leclerq:online">Leclerq:online</a>
      \(L(\theta) \approx \frac{1}{N} \sum_{i=1}^{N} \mathbb{1}\left(d\left(y_{o}^{(i)}, y^{\circ}\right) \leq \epsilon\right)\)
    </p>

    <ol>
      <li class="fragment appear">Rejects most samples when \(\epsilon\) is small</li>
      <li class="fragment appear"><p>
	  Does not make assumptions about the shape of \(L(\theta)\)
	</p>
	<aside class="notes">
	  <ol>
	    <li>Dependency of L on \thqeta is via the parameter used to generate theta, if we moved the threshold by just a little bit we don‚Äôt constrain the likelihood to be similar at all; no constraint on likelihood‚Äôs smoothness at all. Algorithm is given a lot of freedom but it becomes expensive. A lot of dependency on theta, as opposed to depending on say smoothness constraint.</li>

	  </ol>

      </aside></li>
      <li class="fragment appear"><p>
	  Does not use all information available.
	</p>
	<aside class="notes">
	  <ol>
	    <li>You could, say, stop early after many rejections and conclude that the likelihood is low with high certainty.</li>

	  </ol>

      </aside></li>
      <li class="fragment appear"><p>
	  Aims at equal accuracy for all parameters
	</p>
	<aside class="notes">
	  <ol>
	    <li>Computational effort \(N\) doesn‚Äôt depend on \(\theta\)</li>
	    <li>E.g. prioritise for modal area</li>

	  </ol>

      </aside></li>

    </ol>
  </section>
</section>
<section>
  <section id="slide-sec-">
    <h2 id="org5837883">BOLFI</h2>
    <p width="350">
      <img src="/ox-hugo/screenshot_2019-11-03_16-59-20.png" alt="screenshot_2019-11-03_16-59-20.png" width="350" />
      Image from <a class='org-ref-reference' href="#Leclerq:online">Leclerq:online</a>
    </p>
    <aside class="notes">
      <p>
	<a class='org-ref-reference' href="#Leclerq:online">Leclerq:online</a>
      </p>

    </aside>
    <ol>
      <li class="fragment appear">Does not reject samples; learns from them (i.e. builds a statistical model of the distances w.r.t. the parameters).</li>
      <li class="fragment appear">Models the distances, assuming the average distance is smooth.</li>
      <li class="fragment appear">Use Bayes‚Äô theorem to update the proposal of new points.</li>
      <li class="fragment appear">Prioritize parameter regions with small distances.</li>

    </ol>
  </section>
</section>
<section>
  <section id="slide-sec-">
    <h2 id="orgbc6e982">Regressing effective likelihood</h2>
    <ul>
      <li class="fragment appear">Data are tuples \((\theta_i, d_i)\), where \(d_i = d(\mathbf{y}_\theta^{(i)}, \mathbf{y}_o)\)</li>
      <li class="fragment appear">Model conditional distribution \(d \mid \theta\)</li>
      <li class="fragment appear"><p>
	  Approximate likelihood function for some choice of \(\epsilon\):
	</p>
	<aside class="notes">
	  <ul>
	    <li>Use the probability under that extimated model that the distance is smaller than \(\epsilon\).</li>

	  </ul>

	</aside>
	<ul>
	  <li>\(\hat{L}(\theta) \propto \hat{P}(d\leq \epsilon \mid \theta)\)</li>
	  <li>Choice of \(\epsilon\) is delayed until the end, after the learning of the model.</li>

      </ul></li>

    </ul>
  </section>
</section>
<section>
  <section id="slide-sec-">
    <h3 id="org5eaba76">Regressing effective likelihood</h3>
    <ul>
      <li class="fragment appear">Fit a log Gaussian process (GP) to regress how the parameters affect the distances and use Bayesian optimization.
	<ul>
	  <li>Squared exponential covariance function</li>
	  <li>Log transform because distances are non-negative</li>

      </ul></li>
      <li class="fragment appear">Approach is not restricted to GPs</li>

    </ul>
  </section>
</section>
<section>
  <section id="slide-sec-">
    <h2 id="org345ccd7">Data acquisition</h2>
    <ul>
      <li class="fragment appear">Use Bayesian optimization to prioritize regions of \(\theta\) where \(d\) tends to be small.</li>
      <li class="fragment appear">Sample \(\theta\) from an adaptively constructed proposal distribution, e.g. the lower confidence bound acquisition function.
	<ul>
	  <li>\(\mathcal{A}_{t}(\theta)=\underbrace{\mu_{t}(\theta)}_{\text {post mean }}-\sqrt{\underbrace{\eta_{t}^{2}}_{\text {weight  }} \underbrace{v_t(\theta)}_{\text {post var }}}\), \(t\): no. of samples acquired</li>
	  <li>‚ÄúWe used the simple heuristic that \(\theta_{t+1}\) is sampled from a Gaussian with diagonal covariance and mean equal to the minimizer of the acquisition function. The standard deviations were determined by finding the end-points of the interval where the acquisition function was within a certain (relative) tolerance.‚Äù</li>

      </ul></li>
      <li class="fragment appear">Approach is not restricted to this acquisition function.</li>

    </ul>

  </section>
</section>
<section>
  <section id="slide-sec-">
    <h3 id="org0a6def7">Bayesian optimization in action</h3>
    <p>
      <img src="/ox-hugo/bayesian_optimization_1d.gif" alt="bayesian_optimization_1d.gif" />
      Image from <a class='org-ref-reference' href="#Leclerq:online">Leclerq:online</a>
    </p>
  </section>
</section>
<section>
  <section id="slide-sec-">
    <h3 id="orgf7acc76">Close the loop</h3>
    <p width="400">
      <img src="/ox-hugo/screenshot_2019-11-06_12-08-41.png" alt="screenshot_2019-11-06_12-08-41.png" width="400" />
      Image from <a class='org-ref-reference' href="#10.1093/sysbio/syw077">10.1093/sysbio/syw077</a>
    </p>
    <ul>
      <li class="fragment appear">Exploration: where the uncertainty is high</li>
      <li class="fragment appear">Exploitation: where posterior mean is smallest</li>
      <li class="fragment appear">Use Bayes‚Äô theorem to update the model in light of new data</li>
      <li class="fragment appear">As opposed to usual applications of Bayesian optimization, here the objective function is highly stochastic.</li>

    </ul>
  </section>
</section>
<section>
  <section id="slide-sec-">
    <h2 id="org48389b9">Results</h2>
    <ul>
      <li class="fragment appear">Roughly equal results with 1000x fewer simulations
	<ul>
	  <li>Monte Carlo ABC: 4.5 days with 300 cores</li>
	  <li>BOLFI: 90 minutes with seven cores</li>

      </ul></li>
      <li class="fragment appear">Data of bacterial infections in child care centers.
	<ul>
	  <li>Data generating process is defined via a latent continuous-time Markov chain and an observation model.</li>
	  <li>‚ÄúDeveloped by Numminen et a.l (2013) to infer transmission dynamics of bacterial infections in day care centers.‚Äù</li>

      </ul></li>

    </ul>

  </section>
</section>
<section>
  <section id="slide-sec-">
    <h3 id="org651451d">Figure 12</h3>

    <div class="figure">
      <p><img src="/ox-hugo/screenshot_2019-11-05_21-39-25.png" alt="screenshot_2019-11-05_21-39-25.png" width="450" />
      </p>
    </div>
    <aside class="notes">
      <ul>
	<li>Computational cost on log scale. 6 means a million; 3 means a thousand</li>
	<li>Blue line is reference for the inferred posterior mean at the very end of the standard PMC-ABC posterior method.</li>
	<li>Red line is the best, model-based posterior</li>
	<li>Confidence intervals are wider than conventional approach</li>

      </ul>

    </aside>
  </section>
</section>
<section>
  <section id="slide-sec-">
    <h2 id="orgb711f48">Advantages</h2>
    <ul>
      <li class="fragment appear">Inference more efficient, far more comprehensive data analysis.</li>
      <li class="fragment appear">Enables inference for e.g. models of evolution where simulating a single data set takes 12-24 hours.</li>
      <li class="fragment appear">Enables investigation of model identifiability, or the influence of distance measure on likelihood function.
	<ul>
	  <li>We get an explicit construction of an approximate likelihood function, whereas with conventional ABC only had an implicit likelihood function.</li>

      </ul></li>

    </ul>
  </section>
</section>
<section>
  <section id="slide-sec-">
    <h2 id="org7abd8ec">Further research</h2>
    <ul>
      <li class="fragment appear">Distance measures</li>
      <li class="fragment appear">Acquisition function</li>
      <li class="fragment appear">Efficient high-dimensional inference
	<ul>
	  <li>Use this advantage from Bayesian optimization</li>

      </ul></li>

    </ul>
  </section>
</section>
<section>
  <section id="slide-sec-">
    <h2 id="org9dc9db8">Conclusion</h2>
    <p>
      BOLFI combines ‚Ä¶
    </p>
    <ol>
      <li class="fragment appear">Statistical modeling (GP regression) of the distance between observed and simulated data</li>
      <li class="fragment appear">Decision making under uncertainty (Bayesian optimization).</li>

    </ol>
    <p>
      ‚Ä¶to increase efficiency of inference by several orders of magnitude. 
    </p>
  </section>
</section>
<section>
  <section id="slide-sec-">
    <h2 id="orgb40a508">Links and reference Practical</h2>
    <ul>
      <li>Code: <a href="https://github.com/elfi-dev/elfi">https://github.com/elfi-dev/elfi</a></li>
      <li>Demonstration: <a href="https://github.com/elfi-dev/notebooks/blob/master/BOLFI.ipynb">https://github.com/elfi-dev/notebooks/blob/master/BOLFI.ipynb</a></li>
      <li><a href="https://www.youtube.com/watch?v=orDbPZFd7Gk">Video: "Bayesian optimization for likelihood-free cosmological inference"</a>
	<ul>
	  <li><a href="http://www.florent-leclercq.eu/talks/2018-10-22_IHP.pdf">http://www.florent-leclercq.eu/talks/2018-10-22_IHP.pdf</a></li>
	  <li><a href="http://www.florent-leclercq.eu/talks/2019-05-30_Lancaster.pdf">http://www.florent-leclercq.eu/talks/2019-05-30_Lancaster.pdf</a></li>
	  <li><a href="https://www.aquila-consortium.org/method/lfi.html">https://www.aquila-consortium.org/method/lfi.html</a></li>

      </ul></li>
      <li><a href="https://www.youtube.com/watch?v=pEUL5UFZsY4">Video: "Michael Gutmann: Bayesian Optimization for Likelihood-Free Inference - GPSS 2016"</a>
	<ul>
	  <li><a href="https://michaelgutmann.github.io/assets/slides/Gutmann-2016-09-16.pdf">https://michaelgutmann.github.io/assets/slides/Gutmann-2016-09-16.pdf</a></li>
	  <li><a href="https://academic.oup.com/sysbio/article/66/1/e66/2420817">https://academic.oup.com/sysbio/article/66/1/e66/2420817</a></li>

      </ul></li>

    </ul>
  </section>
</section>
<section>
  <section id="slide-sec-">
    <h2 id="orgc76416b">Bibliography</h2>
    <p>
      <h1 class='org-ref-bib-h1'>Bibliography</h1>
      <ul class='org-ref-bib'><li><a id="10.1093/sysbio/syw077">[10.1093/sysbio/syw077]</a> <a name="10.1093/sysbio/syw077"></a>Lintusaari, Gutmann, Dutta, Kaski & Corander, Fundamentals and Recent Developments in Approximate Bayesian Computation, <i>Systematic Biology</i>, <b>66(1)</b>, e66-e82 (2016). <a href="https://doi.org/10.1093/sysbio/syw077">link</a>. <a href="http://dx.doi.org/10.1093/sysbio/syw077">doi</a>.</li>
	<li><a id="Leclerq:online">[Leclerq:online]</a> <a name="Leclerq:online"></a>@miscLeclerq:online,
	  author = Florent Leclercq,
	  title = Bayesian optimisation for likelihood-free cosmological inference,
	  howpublished = \urlhttp://www.florent-leclercq.eu/talks/2018-10-22_IHP.pdf,
	  month = ,
	  year = ,
	  note = (Accessed on 11/03/2019. Recording at https://www.youtube.com/watch?v=orDbPZFd7Gk&t=41s.)
	</li>
      </ul>
    </p>
  </section>
</section>
</div>
</div>
<script src="https://cdn.jsdelivr.net/reveal.js/3.0.0/lib/js/head.min.js"></script>
<script src="https://cdn.jsdelivr.net/reveal.js/3.0.0/js/reveal.js"></script>

<script>
  // Full list of configuration options available here:
  // https://github.com/hakimel/reveal.js#configuration
  Reveal.initialize({

    controls: false,
    progress: true,
    history: false,
    center: true,
    slideNumber: 'c',
    rollingLinks: false,
    keyboard: true,
    overview: true,

    theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
    transition: Reveal.getQueryHash().transition || 'none', // default/cube/page/concave/zoom/linear/fade/none
    transitionSpeed: 'default',
    multiplex: {
      secret: '', // null if client
      id: '', // id, obtained from socket.io server
      url: '' // Location of socket.io server
    },

    // Optional libraries used to extend on reveal.js
    dependencies: [
      { src: 'https://cdn.jsdelivr.net/reveal.js/3.0.0/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }]
  });
</script>
</body>
</html>
